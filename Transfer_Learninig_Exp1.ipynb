{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import visualkeras\n",
    "import read_data_tensorflow as read_data\n",
    "import threading\n",
    "import tqdm.notebook as tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "#############################################\n",
    "#load data, fashion MNIST\n",
    "org_train_images, train_labels, test_images, test_labels = read_data.load_fashion_mnist_dataset()\n",
    "\n",
    "#load data, MNIST\n",
    "#org_train_images, train_labels, test_images, test_labels = read_data.load_mnist_dataset()\n",
    "\n",
    "train_images = np.expand_dims(org_train_images, 3) #train x\n",
    "train_images = train_images.astype(np.float32)\n",
    "org_train_images = org_train_images.astype(np.float32)\n",
    "test_images = np.expand_dims(test_images, 3)       #test x\n",
    "test_images = test_images.astype(np.float32)\n",
    "\n",
    "train_labels = train_labels.astype(np.float32)     #train y\n",
    "test_labels = test_labels.astype(np.float32)       #test y\n",
    "\n",
    "#normalize all data\n",
    "train_images = train_images /255.0\n",
    "test_images = test_images   /255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use multiple 1 filter CNN layer to comprise a multi filter CNN layer\n",
    "\n",
    "#ideas for reducing resolution by factor of 2\n",
    "#1. use 4x4 filter and stride 2\n",
    "#2. use 2x2 filter and stride 2\n",
    "#3. use a flatten layer for computation (?)\n",
    "\n",
    "#customized activation function\n",
    "def bell_tanh_activation(x):\n",
    "    #shapes like a bell\n",
    "    #when x in 0 to 1, y approaches 1\n",
    "    #and decreases on both sides and approaches -1\n",
    "    #use 5+5x tanh\n",
    "    x1 = 10-5*x\n",
    "    x2 = 5*x\n",
    "    return tf.minimum(tf.tanh(x1), tf.tanh(x2))\n",
    "    \n",
    "def gaussian_activation(x, tilt_level = 0.85): #last best -- 1.1\n",
    "    x = tilt_level-tilt_level*x\n",
    "    return 2*tf.exp(-(x**2)) - 1 #range -1 to 1\n",
    "\n",
    "\n",
    "def gaussian_activation_01(x, tilt_level = 1):#0.85): #last best -- 1.1\n",
    "    #x = tilt_level-tilt_level*x\n",
    "    return tf.exp(-(x**2)) #range 0 to 1\n",
    "\n",
    "\n",
    "#sigmoid\n",
    "#1/(1+e^-x)\n",
    "\n",
    "#======================================================================\n",
    "# Notes:\n",
    "# proves that sigmoid is better, for unknown reason\n",
    "# probably because the gradient is non-zero for all values of x\n",
    "# In contrast, bell has gradient approaching 0 not only on two ends, but in middle, and hence is harder to train\n",
    "#======================================================================\n",
    "\n",
    "\n",
    "\n",
    "class extensible_CNN_layer_multi_module_3D(tf.keras.Model):\n",
    "    #growth model\n",
    "    #input: nxnx1\n",
    "    #output: 1*n\n",
    "    #filter number can increase\n",
    "    #last parameter:\n",
    "    # kernel_size = (4,4), stride = 2, activation = 'gaussian_bell', padding = 'valid', optimizer = 'adam'\n",
    "    #best: gaussian bell of 1 tilt level, with reg on weight and bias, and 3x3 filter with stride 1\n",
    "    def __init__(self, kernel_size = (4,4,1), stride = 2, activation = 'sigmoid', padding = 'valid', optimizer = 'adam'): #best -- gaussian_bell, 4x4, stride 2\n",
    "        super(extensible_CNN_layer_multi_module_3D, self).__init__()\n",
    "        self.filter_list = []\n",
    "        self.bias_list = []\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.channels = 1\n",
    "        self.threshold = 0.5\n",
    "        if self.activation == \"gaussian_bell\":\n",
    "            self.threshold = 0.4 #0.34 final -- 0.4 one layer\n",
    "        if self.activation == \"sigmoid\":\n",
    "            self.threshold = 0.8 #from 0.5 to 0.7, unstable\n",
    "        if self.activation == \"relu\":\n",
    "            self.threshold = 0.5\n",
    "        if self.activation == \"gaussian_bell_01\":\n",
    "            self.threshold = 0.5 #last 0.5    \n",
    "        \n",
    "        if (activation == 'bell_tanh'):\n",
    "            self.activation = bell_tanh_activation\n",
    "        if (activation == 'gaussian_bell'):\n",
    "            self.activation = gaussian_activation\n",
    "        if (activation == 'gaussian_bell_01'):\n",
    "            self.activation = gaussian_activation_01\n",
    "         \n",
    "\n",
    "        \n",
    "        \n",
    "        self.padding = padding\n",
    "        self.optimizer = optimizer\n",
    "        if optimizer == 'adam':\n",
    "            #self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "            #use legacy optimizer\n",
    "            self.optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.1)\n",
    "            \n",
    "        else:\n",
    "            print(\"\\noptimizer not implemented\\n\")\n",
    "            return\n",
    "        \n",
    "        self.sample_space = {}\n",
    "        self.filter_list = [] \n",
    "        #initialized with 1 filter\n",
    "        self.aggregated_conv = None\n",
    "    \n",
    "    def call(self, input_x):\n",
    "        #input\n",
    "        feature_maps = []\n",
    "        for filter_i in self.filter_list:\n",
    "            feature_maps.append(filter_i(input_x))\n",
    "        #feature map of a conv3d layer is: (batch, height, width, depth, channels)\n",
    "        #ignore batch and channels\n",
    "        #concatenate the 3D feature maps on the depth axis\n",
    "        #print(\"feature_maps shape: \", feature_maps[0].shape)\n",
    "        \n",
    "        #print(len(feature_maps), feature_maps[0].shape)\n",
    "        feature_maps = tf.concat(feature_maps, axis = 3)\n",
    "        #print(\"feature_maps shape: \", feature_maps.shape)\n",
    "        #Final shape -- (batch, height, width, depth, channels), where batch and channels are 1\n",
    "        return feature_maps\n",
    "    \n",
    "    def update_depth(self, new_depth):\n",
    "        #because with change of previous layer's units, the depth of inputs to this layer changes\n",
    "        #So update the depth in all filters and sample space of this layer\n",
    "        #filter_list -- list\n",
    "        #sample_space -- dict -- key: filter_index, value: sample\n",
    "        print(\"original depth: \", self.filter_list[0].get_weights()[0].shape)\n",
    "        self.kernel_size = (self.kernel_size[0], self.kernel_size[1], new_depth) #update kernel size for new depth\n",
    "        for filter_index in range(len(self.filter_list)):\n",
    "            filter_depth = self.filter_list[filter_index].kernel_size[2] #filter depth\n",
    "            if filter_depth > new_depth:\n",
    "                #this might be caused by an error\n",
    "                print(\"filter depth is larger than new depth\\nOnly increase is allowed at this version\")\n",
    "                return\n",
    "            if filter_depth == new_depth:\n",
    "                #no need to update\n",
    "                continue\n",
    "            \n",
    "            #create a new filter\n",
    "            new_filter = tf.keras.layers.Conv3D(filters = 1, kernel_size = self.kernel_size, strides = self.stride, padding = self.padding, activation = self.activation)\n",
    "            #weights\n",
    "            new_filter.build(input_shape = (1, self.kernel_size[0], self.kernel_size[1], new_depth, 1))\n",
    "            new_filter_weights = np.zeros((self.kernel_size[0], self.kernel_size[1], self.kernel_size[2], 1, 1)).astype('float32') #initialize with 0\n",
    "            #reduce the newly added weights by 1/sum(newly added weights)\n",
    "            count_new_weights = self.kernel_size[0]*self.kernel_size[1]*(self.kernel_size[2]-filter_depth)\n",
    "            reduce_map = np.zeros((self.kernel_size[0], self.kernel_size[1], self.kernel_size[2], 1, 1)).astype('float32') #initialize with 0\n",
    "            reduce_map[:, :, :, :, :] -= 2/(new_depth - filter_depth) #reduce by 1/sum(newly added weights) for the newly added weights\n",
    "            \n",
    "            #a different reduce map will result in different mode. Current mode --> inclusive, may recognize some new patterns as its own class\n",
    "            #add the old weights\n",
    "            old_weights = self.filter_list[filter_index].get_weights()[0]\n",
    "            new_filter_weights[:, :, :filter_depth, 0, 0] += old_weights[:, :, :, 0, 0] #reduce_map[:, :, filter_depth:, 0, 0]\n",
    "            #add the reduce map\n",
    "            new_filter_weights[:, :, filter_depth:, 0, 0] += reduce_map[:, :, filter_depth:, 0, 0]\n",
    "            #add the old weights to the new filter and reduced weights to the new filter\n",
    "            new_bias = self.filter_list[filter_index].get_weights()[1]\n",
    "            \n",
    "            #set the new weights\n",
    "            new_filter.set_weights([new_filter_weights, new_bias])\n",
    "            #update the filter\n",
    "            self.filter_list[filter_index] = new_filter\n",
    "            \n",
    "            #update the sample space\n",
    "            sample_i = self.sample_space[filter_index]\n",
    "            #add 0s to the end of the sample\n",
    "            zero_sample = np.zeros((1, self.kernel_size[0], self.kernel_size[1], self.kernel_size[2], 1)).astype('float32')\n",
    "            zero_sample[0, :, :, :filter_depth, 0] += sample_i[0, :, :, :, 0]\n",
    "            #update the sample space\n",
    "            self.sample_space[filter_index] = zero_sample\n",
    "        #at the end, print a message to show the update is done\n",
    "        #take the first filter's shape as example\n",
    "        first_filter_shape = self.filter_list[0].get_weights()[0].shape\n",
    "        \n",
    "        print(\"update of layer's depth done, new depth: \", first_filter_shape)\n",
    "        print(\"new sample space shape: \", self.sample_space[0].shape)\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    def add_filter(self, x, epochs = 10, refit = False, regularization = True, image_x = None):\n",
    "        #use autoencoder to generate a new filter which accepts x\n",
    "        #x: nxnxnx1\n",
    "        #check if x is fit for filter size\n",
    "        \n",
    "        if x.shape != (self.kernel_size[0], self.kernel_size[1], self.kernel_size[2], 1):\n",
    "            print(\"x is not fit for filter size\")\n",
    "            print(\"x shape: \", x.shape)\n",
    "            print(\"expected shape: \", (self.kernel_size[0], self.kernel_size[1], self.kernel_size[2], 1))\n",
    "            return\n",
    "        \n",
    "        #reshape x to (1, nxnxn, 1)\n",
    "        x = x.reshape(1, self.kernel_size[0], self.kernel_size[1], self.kernel_size[2], 1) #for 3D conv\n",
    "        #check if x is equivalent to any existing filter's sample space\n",
    "        for sample_i in self.sample_space.keys():\n",
    "            if np.sum(abs(self.sample_space[sample_i] - x)) < 0.2:\n",
    "                print(\"x is already in sample space\")\n",
    "                return\n",
    "        \n",
    "        \n",
    "        #initialize a new filter with decoder\n",
    "\n",
    "        new_filter = tf.keras.layers.Conv3D(1, self.kernel_size, \n",
    "                                            padding=self.padding, activation=self.activation,strides=self.stride)\n",
    "        decoder = tf.keras.layers.Conv3DTranspose(1, self.kernel_size, \n",
    "                                                  padding=self.padding, activation=self.activation,strides=self.stride)\n",
    "        \n",
    "        #set weights of new filter to be the same as x\n",
    "        print(\"new filter initialized, id = \", len(self.filter_list))\n",
    "        \n",
    "        #initialize new filter\n",
    "        \n",
    "        #get the 1 matrix of x\n",
    "        #TODO: use a better way to get the 1 matrix of x\n",
    "        #  by giving a suitable threshold -- example, 0.5\n",
    "        zero_pixel_threshold = 0.1#self.threshold\n",
    "        \n",
    "        #matrix_1 = (x > zero_pixel_threshold).astype(np.float64)\n",
    "        '''\n",
    "        x_mean = np.mean(x)\n",
    "        x_max = np.max(x)\n",
    "        x_threshold = x_mean + (x_max - x_mean)/2 #With the prior knowledge that inputs are sparse, this threshold can separate most of the 1s and 0s\n",
    "        \n",
    "        zero_pixel_threshold = x_mean\n",
    "        matrix_1 = (x > x_mean).astype(np.float64)\n",
    "        matrix_1 = matrix_1 + matrix_1 - 1\n",
    "        print(\"x_mean: \", x_mean, \" matrix_1 mean: \", np.mean(matrix_1), \" matrix_1 sum: \", np.sum(matrix_1))\n",
    "        matrix_1 = matrix_1 - np.mean(matrix_1) - 1/(self.kernel_size[0]*self.kernel_size[1]*self.kernel_size[2])\n",
    "       \n",
    "        matrix_1 = matrix_1/(np.sum(matrix_1))\n",
    "        characterization = x/np.max(x)\n",
    "        '''\n",
    "        \n",
    "        #make the matrix_1, when multiplied by x, the output is 1\n",
    "        #assigning top n to 1, and rest to -1, to make the output of the dot product to be 1\n",
    "        #find the threshold, where the values below and above sum to same value\n",
    "        #because the range of x is 0 to 1, the sum of the values below and above the threshold is 0.5\n",
    "        random_filter = np.random.rand(self.kernel_size[0], self.kernel_size[1], self.kernel_size[2], 1)/5\n",
    "        threshold_same_sum = 0\n",
    "        for i in range(100):\n",
    "            threshold = i/100\n",
    "            x_above = x[x > threshold]\n",
    "            x_below = x[x <= threshold]\n",
    "            if (np.sum(x_above) - np.sum(x_below)) <= 1:\n",
    "                threshold_same_sum = threshold\n",
    "                break\n",
    "        print(\"threshold_same_sum: \", threshold_same_sum)\n",
    "        #x_above = x[x > threshold_same_sum] + np.zeros(x.shape)\n",
    "        #x_below = x[x <= threshold_same_sum] + np.zeros(x.shape)\n",
    "        matrix_1 = np.zeros(x.shape)\n",
    "        matrix_1[x > threshold_same_sum] = 1\n",
    "        matrix_1[x <= threshold_same_sum] = -1\n",
    "        \n",
    "        #mode 0\n",
    "        #if (np.sum(matrix_1) != 0):\n",
    "        #    matrix_1 = matrix_1/np.sum(matrix_1)\n",
    "        \n",
    "        #mode 1    \n",
    "        #matrix_1_positive_sum = np.sum(matrix_1[x > threshold_same_sum])\n",
    "        #matrix_1_negative_sum = np.sum(matrix_1[x <= threshold_same_sum])\n",
    "        #matrix_1[x <= threshold_same_sum] = matrix_1[x <= threshold_same_sum]/(matrix_1_negative_sum / matrix_1_positive_sum)\n",
    "        \n",
    "        #mode 2\n",
    "        matrix_1 = np.multiply(matrix_1, x)\n",
    "        \n",
    "        #mode 3\n",
    "        \n",
    "        #matrix_1 = x - threshold_same_sum\n",
    "        \n",
    "        #matrix_1 = (x - np.mean(x))\n",
    "        #square\n",
    "        #matrix_1 = np.multiply(matrix_1, abs(matrix_1))\n",
    "        #matrix_1 = matrix_1/np.max(abs(matrix_1))\n",
    "        \n",
    "        \n",
    "        \n",
    "        bias = np.array([-1]) #0\n",
    "        \n",
    "        if (np.max(x) > zero_pixel_threshold):\n",
    "            #characterization =(x/np.max(x))\n",
    "            #equals to the 1 matrix of x\n",
    "            #random_filter = np.random.rand(3,3,1)/5\n",
    "            \n",
    "            #avoid a random_filter value on pixel <= 0\n",
    "            #multiply by dot product of matrix_1 and random_filter\n",
    "            random_filter = np.multiply(matrix_1, random_filter)\n",
    "            \n",
    "            #devide by 5 so that the maximum output is 0.2*16 - 1 = 2.2\n",
    "            #characterization = characterization/5  #/np.average(characterization)\n",
    "            \n",
    "            #or divide by the size of the filter, setting bias to 0, so the output is 1\n",
    "            \n",
    "            #bias = np.array([-np.sum(matrix_1)])\n",
    "            bias = np.array([-(np.sum(np.multiply(matrix_1, x)))])\n",
    "            '''          \n",
    "            characterization = (matrix_1)# + x) - random_filter\n",
    "            matrix_n1 = matrix_1 - 1 #if is 0, then -1\n",
    "            #matrix_n1 *= (np.sum(characterization))\n",
    "            characterization = characterization + matrix_n1\n",
    "            \n",
    "            characterization -= random_filter\n",
    "            characterization -= np.mean(characterization)\n",
    "            '''\n",
    "            \n",
    "            #V3\n",
    "            characterization = (matrix_1)# - zero_pixel_threshold\n",
    "            print(\"characterization shape = \", characterization.shape, \"bias = \", float(bias))\n",
    "            #characterization -= random_filter\n",
    "            #print(\"characterization = \", characterization)\n",
    "            print(np.sum(characterization))\n",
    "            #characterization = characterization/np.sum(characterization) #so when product with x, the output is 1\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            bias = np.array([1])\n",
    "            characterization = x - 2*(bias)    #/(np.max(x)+0.01)\n",
    "            #print(characterization)\n",
    "            \n",
    "        #print(\"characterization = \", characterization, \"matrix_1 = \", matrix_1)\n",
    "        #characterization = np.asarray(characterization - 1 + matrix_1).reshape(1,self.kernel_size[0],self.kernel_size[1],1).astype(np.float64)\n",
    "        characterization = np.asarray(characterization).reshape(1,self.kernel_size[0],self.kernel_size[1], self.kernel_size[2], 1).astype(np.float64)\n",
    "        \n",
    "        #normalize\n",
    "        #characterization = characterization/np.max(characterization)\n",
    "        new_filter.build(input_shape = (1,self.kernel_size[0],self.kernel_size[1],self.kernel_size[2],1))\n",
    "        weight = characterization.reshape(self.kernel_size[0],self.kernel_size[1],self.kernel_size[2],1,1)\n",
    "        new_filter.set_weights([weight, bias])\n",
    "        decoder.build(input_shape = (1,1,1,1,1))\n",
    "        decoder.set_weights([weight, bias])\n",
    "        #the weight of this filter is characterized by x\n",
    "\n",
    "        #train the new filter\n",
    "        #new filter must reject all other x in the sample space\n",
    "        self.filter_list.append(new_filter)\n",
    "        \n",
    "        def calc_reg(weight, bias):\n",
    "            reg = 0\n",
    "            #reg = tf.reduce_sum((tf.square(weight)))# + tf.reduce_sum(tf.square(bias))\n",
    "            #reg = tf.reduce_sum((weight))\n",
    "            #reg += tf.reduce_sum(bias)\n",
    "            #reg += tf.reduce_sum(tf.square(bias))\n",
    "            #reg = tf.square(reg)\n",
    "            \n",
    "            return reg\n",
    "            \n",
    "        #==============================================\n",
    "        #sub-functions that can be reused in this function\n",
    "        def call_autoencoder(x):\n",
    "            y = new_filter(x)\n",
    "            y = decoder(y)\n",
    "            #because decoder has activation, so y is in range [0,1]\n",
    "            #hence magnify y by max in x\n",
    "            y = y * np.max(x)\n",
    "            return y\n",
    "        \n",
    "        \n",
    "        def fit_autoencoder(x):\n",
    "            '''\n",
    "            autoencoder = tf.keras.Model(new_filter.input, call_autoencoder(new_filter.input))\n",
    "            autoencoder.compile(optimizer=self.optimizer, loss=self.loss)\n",
    "            autoencoder.fit(x, x, epochs=epochs, verbose=0)\n",
    "            '''\n",
    "\n",
    "            #use gradient descent to train the new filter\n",
    "            #consider the sample space and the autoencoder \n",
    "            \n",
    "            loss = 0\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                y = call_autoencoder(x)\n",
    "                #use sum of square error as loss function\n",
    "                loss = tf.reduce_sum(tf.square(y - x))\n",
    "                #a regularization by calculating sum of weights\n",
    "                if regularization:\n",
    "                    loss += calc_reg(new_filter.weights[0], new_filter.weights[1])\n",
    "                    #loss += tf.reduce_sum((new_filter.weights[0]))# + new_filter.weights[1]))\n",
    "            grad_filter = tape.gradient(loss, new_filter.trainable_variables)\n",
    "            grad_decoder = tape.gradient(loss, decoder.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(grad_filter, new_filter.trainable_variables))\n",
    "            self.optimizer.apply_gradients(zip(grad_decoder, decoder.trainable_variables))\n",
    "            #clear tape\n",
    "            tf.keras.backend.clear_session()\n",
    "            return loss\n",
    "        \n",
    "        def fit_filter(negative_samples):\n",
    "            loss = 0\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                y = new_filter(negative_samples)\n",
    "                #expect y to be close to -1\n",
    "                loss = tf.reduce_sum(tf.square(y) - -1)\n",
    "                if regularization:\n",
    "                    #make weights close to a sum of 1\n",
    "                    loss += calc_reg(new_filter.weights[0], new_filter.weights[1])\n",
    "                    #loss += tf.reduce_sum((new_filter.weights[0]))# + new_filter.weights[1]))\n",
    "                #the square makes loss reduce faster, so more tolerant to negative samples\n",
    "            grad_filter = tape.gradient(loss, new_filter.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(grad_filter, new_filter.trainable_variables))\n",
    "            #clear tape\n",
    "            tf.keras.backend.clear_session()\n",
    "            return loss\n",
    "        \n",
    "        def combined_fit(target, negative_samples):\n",
    "            loss = 0\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                y = call_autoencoder(target)\n",
    "                #use sum of square error as loss function\n",
    "                loss = tf.reduce_sum(tf.square(y - target))\n",
    "                #expect y to be close to 0\n",
    "                z = new_filter(negative_samples)\n",
    "                target_z = -1#-1\n",
    "                #target_z = z - self.threshold\n",
    "                loss += tf.reduce_sum(tf.square(z - target_z))# (0 - (1-self.threshold)))) #far from threshold\n",
    "                #loss += tf.reduce_sum(tf.square(new_filter(negative_samples))) #targetting for 0\n",
    "                loss += (tf.reduce_sum(tf.square(new_filter(target) - 1))) #targetting for 1\n",
    "\n",
    "                #the above calculations can be improved\n",
    "                if regularization:\n",
    "                    loss += calc_reg(new_filter.weights[0], new_filter.weights[1])\n",
    "                    #loss += tf.reduce_sum((new_filter.weights[0]))# + new_filter.weights[1]))\n",
    "            grad_filter = tape.gradient(loss, new_filter.trainable_variables)\n",
    "            grad_decoder = tape.gradient(loss, decoder.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(grad_filter, new_filter.trainable_variables))\n",
    "            #last best not update decoder\n",
    "            self.optimizer.apply_gradients(zip(grad_decoder, decoder.trainable_variables))\n",
    "            #clear tape\n",
    "            tf.keras.backend.clear_session()\n",
    "            return loss\n",
    "        #==============================================\n",
    "        \n",
    "        def combined_fit_v2(target, negative_samples):\n",
    "            loss = 0\n",
    "            \n",
    "            #the negative samples in this version is a list of all negative samples\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                y = call_autoencoder(target)\n",
    "                #use sum of square error as loss function\n",
    "                loss = tf.reduce_sum(tf.square(y - target))\n",
    "                #expect y to be close to 0\n",
    "                #fetch the loss of each negative sample\n",
    "                for neg_sample in negative_samples:\n",
    "                    z = new_filter(neg_sample)\n",
    "                    target_z = -1#-1\n",
    "                    loss += tf.reduce_sum(tf.square(z - target_z))/(len(negative_samples)+1) #the averaged loss\n",
    "                    loss += (tf.reduce_sum(tf.square(new_filter(target) - 1)))#/(len(negative_samples)+1)\n",
    "                \n",
    "                if regularization:\n",
    "                    loss += calc_reg(new_filter.weights[0], new_filter.weights[1])\n",
    "                    #loss += tf.reduce_sum((new_filter.weights[0]))# + new_filter.weights[1]))\n",
    "                    \n",
    "            grad_filter = tape.gradient(loss, new_filter.trainable_variables)\n",
    "            grad_decoder = tape.gradient(loss, decoder.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(grad_filter, new_filter.trainable_variables))\n",
    "            #last best not update decoder\n",
    "            self.optimizer.apply_gradients(zip(grad_decoder, decoder.trainable_variables))\n",
    "            #clear tape\n",
    "            tf.keras.backend.clear_session()\n",
    "            return loss\n",
    "        \n",
    "        \n",
    "        def combined_fit_v3(target, negative_samples):\n",
    "            loss = 0\n",
    "            \n",
    "            #the negative samples in this version is a list of all negative samples\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                y = call_autoencoder(target)\n",
    "                #use sum of square error as loss function\n",
    "                loss = tf.reduce_sum(tf.square(y - target))\n",
    "                #expect y to be close to 0\n",
    "                #fetch the loss of each negative sample\n",
    "                loss += (tf.reduce_sum(tf.square(new_filter(target) - 1)))\n",
    "                \n",
    "                for neg_sample in negative_samples:\n",
    "                    z = new_filter(neg_sample)\n",
    "                    target_z = 0#-1, make the negative samples always exist in loss back propagation instead of ignoring it during training\n",
    "                    loss += tf.reduce_sum(tf.square(z - target_z))/(len(negative_samples)+1) #the averaged loss\n",
    "                    #/(len(negative_samples)+1)\n",
    "                #if the depth is greater than 3, then it is after another layer. Use regularization\n",
    "                if self.kernel_size[2] > 3:\n",
    "                    #regularization -- make the weights close to 0\n",
    "                    loss += np.sum(np.square(new_filter.weights[0]))\n",
    "                \n",
    "                \n",
    "                    \n",
    "            grad_filter = tape.gradient(loss, new_filter.trainable_variables)\n",
    "            grad_decoder = tape.gradient(loss, decoder.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(grad_filter, new_filter.trainable_variables))\n",
    "            #last best not update decoder\n",
    "            self.optimizer.apply_gradients(zip(grad_decoder, decoder.trainable_variables))\n",
    "            #clear tape\n",
    "            tf.keras.backend.clear_session()\n",
    "            return loss\n",
    "        \n",
    "        #\n",
    "        progress_bar = tf.keras.utils.Progbar(epochs)\n",
    "        \n",
    "\n",
    "        '''\n",
    "        print(\"\\ncombined training\")\n",
    "        for epoch in (range(epochs)):\n",
    "            loss = 0\n",
    "            for i in range(len(self.filter_list) - 1):\n",
    "                loss = combined_fit(x, self.sample_space[i])\n",
    "            progress_bar.update(epoch, values=[(\"loss\", loss)])\n",
    "        ''' \n",
    "        \n",
    "        print(\"\\ncombined training v3\")\n",
    "        neg_samples = []\n",
    "        for i in range(len(self.filter_list) - 1):\n",
    "            neg_samples.append(self.sample_space[i])\n",
    "        for epoch in (range(epochs)):\n",
    "            loss = 0\n",
    "            loss = combined_fit_v3(x, neg_samples)\n",
    "            progress_bar.update(epoch, values=[(\"loss\", loss)])\n",
    "        \n",
    "            \n",
    "        \n",
    "        self.sample_space[len(self.filter_list) - 1] = x #.reshape(1, self.kernel_size[0], self.kernel_size[1], 1) #add to sample space\n",
    "\n",
    "        \n",
    "        self.filter_list[len(self.filter_list) - 1] = new_filter #replace the filter\n",
    "        \n",
    "        \n",
    "        if image_x is not None:\n",
    "            print(\"\\nUpdating the sample space\")\n",
    "            #get the feature map for different filters\n",
    "            for filter_i in range(max(len(self.filter_list) - 5,0), len(self.filter_list)):\n",
    "                feature_map = self.filter_list[filter_i](image_x)\n",
    "                #get one of the max value's location\n",
    "                max_loc_fm = np.unravel_index(np.argmax(feature_map, axis=None), feature_map.shape)#[0]\n",
    "                #print(max_loc_fm, feature_map.shape, image_x.shape)\n",
    "                #map back to the image_x\n",
    "                org_x = max_loc_fm[1]*self.stride\n",
    "                org_y = max_loc_fm[2]*self.stride\n",
    "                org_z = max_loc_fm[3]*self.stride\n",
    "                #find the patch from image_x\n",
    "                self.sample_space[filter_i] = image_x[:, \n",
    "                                                      (org_x):(org_x + self.kernel_size[0]), \n",
    "                                                      (org_y):(org_y + self.kernel_size[1]), \n",
    "                                                        (org_z):(org_z + self.kernel_size[2]),\n",
    "                                                      :].reshape(1, self.kernel_size[0], self.kernel_size[1], self.kernel_size[2], 1)\n",
    "\n",
    "        if refit:\n",
    "            #fit all the filters\n",
    "            self.refit_all(epochs = epochs)\n",
    "        \n",
    "        return new_filter\n",
    "    \n",
    "    \n",
    "    def refit_all(self, epochs = 100, image_x = None):\n",
    "        #refit all the filters with their own sample (1) and other filters' samples (-1)\n",
    "        #update the sample space\n",
    "                \n",
    "        def refit_filter(idx, epochs):\n",
    "            print(\"\\nrefitting filter \", idx)\n",
    "            progress_bar = tf.keras.utils.Progbar(epochs)\n",
    "            for epoch in range(epochs):\n",
    "                filter_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "                loss = 0\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    \n",
    "                    #fit the filter\n",
    "                    for i in range(len(self.filter_list)):\n",
    "                        if (i == idx):\n",
    "                            loss += tf.reduce_sum(tf.square(self.filter_list[i](self.sample_space[i]) - 1))\n",
    "                        else:\n",
    "                            loss += tf.reduce_sum(tf.square(self.filter_list[i](self.sample_space[i]) - -1))\n",
    "                grad_filter = tape.gradient(loss, self.filter_list[idx].trainable_variables)\n",
    "                filter_optimizer.apply_gradients(zip(grad_filter, self.filter_list[idx].trainable_variables))\n",
    "                progress_bar.update(epoch, values=[(\"loss\", loss)])\n",
    "            #clear tape\n",
    "            \n",
    "            tf.keras.backend.clear_session()\n",
    "            \n",
    "        \n",
    "        for i in range(max(int(len(self.filter_list)/2)-1,0), len(self.filter_list)):\n",
    "            refit_filter(i, epochs)\n",
    "    \n",
    "    #TODO: following functions are needed potentially when the learning covers more images\n",
    "    def collapse_check(self, example_img):\n",
    "        #check if the filters are overlapping\n",
    "        return\n",
    "    \n",
    "    def collapse_overlapping(self, example_img):\n",
    "        #collapse the overlapping filters\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_index_map(self, x):\n",
    "        feature_maps = self.call(x)\n",
    "        return np.argmax(feature_maps, axis = 3).reshape(np.shape(feature_maps)[1:-1])\n",
    "    \n",
    "    \n",
    "    def call_seperated_fm(self, x):\n",
    "        feature_maps = []\n",
    "        for i in range(len(self.filter_list)):\n",
    "            feature_maps.append(self.filter_list[i](x))\n",
    "        return feature_maps\n",
    "            \n",
    "    def get_aggregated_conv(self):\n",
    "        #return the aggregated convolutional layer by building a conv layer with the weights in the filter list\n",
    "        #to set layer weights\n",
    "        #kernel_size[0], kernel_size[1], kernel_size[2], channel, len(self.filter_list)\n",
    "        weights = np.zeros((self.kernel_size[0], self.kernel_size[1], self.kernel_size[2], 1, len(self.filter_list)))\n",
    "        biases = np.zeros((len(self.filter_list)))\n",
    "        for i in tqdm.tqdm(range(len(self.filter_list))):\n",
    "            weight_i = self.filter_list[i].get_weights()[0].reshape(self.kernel_size[0], self.kernel_size[1], self.kernel_size[2], 1, 1)\n",
    "            bias_i = self.filter_list[i].get_weights()[1].reshape(1)\n",
    "            weights[:,:,:,0,i] = weight_i[:,:,:,0,0]\n",
    "            biases[i] = bias_i[0]\n",
    "        new_conv = tf.keras.layers.Conv3D(len(self.filter_list), self.kernel_size, strides = self.stride, padding = \"valid\", activation =self.activation)\n",
    "        new_conv.build((None, self.kernel_size[0], self.kernel_size[1], self.kernel_size[2], 1))\n",
    "        self.aggregated_conv = new_conv\n",
    "        return new_conv\n",
    "    \n",
    "    \n",
    "        \n",
    "            \n",
    "#new_filter = customized_CNN_kernel(4, 2, 'relu')\n",
    "\n",
    "def show_indedx_act_map_2D(model, img):\n",
    "    threshold = model.threshold\n",
    "    \n",
    "    #show the index map and activation map\n",
    "    \n",
    "    feature_maps = model.call(img.reshape(1, img.shape[0], img.shape[1], 1))\n",
    "    index_map = np.argmax(feature_maps, axis = 3).reshape(np.shape(feature_maps)[1:-1])\n",
    "    #print(\"!\")\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.imshow(index_map, cmap = \"gist_ncar\")\n",
    "    ax.set_title(\"index map\")\n",
    "    \n",
    "    #print(\"index map shape\", index_map.shape)\n",
    "    activated_points = np.zeros(np.shape(index_map))\n",
    "    mapping = np.max(feature_maps, axis = 3).reshape(np.shape(feature_maps)[1:-1])\n",
    "    activated_points[mapping > 0.5] = 1\n",
    "    \n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(mapping, cmap = \"gray\")\n",
    "    print(\"min and max\", np.min(mapping), np.max(mapping))\n",
    "    #plt.set_title(\"activated points\")\n",
    "    \n",
    "    fig.show()\n",
    "    plt.show()\n",
    "    \n",
    "def show_all_index_maps_2D(model, data_0_9):\n",
    "    #show the heatmap of 10 images\n",
    "    #show 20 images\n",
    "    figure = plt.figure(figsize=(20, 20))\n",
    "\n",
    "\n",
    "    #show the heatmap of 10 images and 10 original images\n",
    "    #5 images one row\n",
    "\n",
    "    for i in range(len(images_x_0_9)):\n",
    "        feature_maps = tf.convert_to_tensor(my_model.call(images_x_0_9[i]).numpy().astype('float64'))\n",
    "        plt.subplot((len(images_x_0_9) * 2) // 5, 5, i+1 + (i // 5) * 5)\n",
    "        plt.imshow(images_x_0_9[i].reshape(28,28), cmap='gray')\n",
    "        plt.title(\"label \"+ str(i))\n",
    "        plt.subplot((len(images_x_0_9) * 2) // 5, 5, i+6 + (i // 5) * 5)\n",
    "        index_map = np.argmax(feature_maps, axis = 3).reshape(np.shape(feature_maps)[1:-1])\n",
    "        plt.imshow(index_map, cmap='gist_ncar')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def show_all_index_maps_3D(model, data_0_9):\n",
    "    figure = plt.figure(figsize=(20, 20))\n",
    "    \n",
    "    for i in range(len(data_0_9)):\n",
    "        \n",
    "        feature_maps = tf.convert_to_tensor(model.call(data_0_9[i]).numpy().astype('float64'))\n",
    "        plt.subplot((len(data_0_9) * 2) // 5, 5, i+1 + (i // 5) * 5)\n",
    "        plt.imshow(images_x_0_9[i].reshape(28,28), cmap='gray')\n",
    "        plt.title(\"label \"+ str(i))\n",
    "        plt.subplot((len(data_0_9) * 2) // 5, 5, i+6 + (i // 5) * 5)\n",
    "        index_map = np.argmax(feature_maps, axis = 3).reshape(np.shape(feature_maps)[1:-2])\n",
    "        plt.imshow(index_map, cmap='gist_ncar')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "images_x_0_9 = []\n",
    "for i in range(10):\n",
    "    images_x_0_9.append(train_images[np.where(train_labels == i)[0][0]])\n",
    "    \n",
    "fm_0_9 = []\n",
    "#give the feature maps processed by first layer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_filter(image, model, image_shape, fm_0_9):\n",
    "    if image_shape[2] > model.kernel_size[2]:\n",
    "        model.update_depth(image_shape[2])\n",
    "    print(\"image shape\", image_shape)\n",
    "    kernel_size = model.kernel_size\n",
    "    stride = model.stride\n",
    "    #image_shape ---> (x, y, z)\n",
    "    image = image.reshape(1, image_shape[0], image_shape[1], image_shape[2], 1)\n",
    "    feature_map_size_xy = (image_shape[0] - kernel_size[0]) // stride + 1\n",
    "    feature_map_size_z = (image_shape[2] - kernel_size[2]) // stride + 1\n",
    "    feature_map_size = (feature_map_size_xy, feature_map_size_xy, feature_map_size_z)\n",
    "\n",
    "    if len(model.filter_list) == 0:\n",
    "        null_input = np.zeros((kernel_size[0], kernel_size[1], kernel_size[2], 1))\n",
    "        new_filter = model.add_filter(null_input, epochs = 100)\n",
    "        \n",
    "        if new_filter is None:\n",
    "            print(\"ERROR null filter\")\n",
    "    \n",
    "    feature_maps = model.call(image.reshape(1, image_shape[0], image_shape[1], image_shape[2], 1))\n",
    "    #feature map size --  1, x, y, z, 1\n",
    "    #separate to multiple feature maps corresponding back to different filters\n",
    "    feature_maps_of_filters = []\n",
    "    \n",
    "    for i in range(len(model.filter_list)):\n",
    "        depth_start = i * feature_map_size[2]\n",
    "        depth_end = (i+1) * feature_map_size[2]\n",
    "        feature_maps_of_filters.append(feature_maps[:, :, :, depth_start:depth_end, :])\n",
    "    #add together and divide by the number of filters\n",
    "    \n",
    "    #find the maximum values within the feature maps\n",
    "    #print(model)\n",
    "    max_values_on_maps = np.zeros(feature_map_size)\n",
    "    for fm in feature_maps_of_filters:\n",
    "        fm = (fm>model.threshold).numpy().astype(np.float32)\n",
    "        max_values_on_maps += fm.reshape(feature_map_size)\n",
    "    \n",
    "    \n",
    "    inactive_points = np.where(max_values_on_maps == 0)\n",
    "    inactive_ratio_0 = len(inactive_points[0])/np.prod(np.shape(max_values_on_maps))\n",
    "    #check how many points are inactive\n",
    "    print (\"inactive ratio \", inactive_ratio_0)\n",
    "    \n",
    "    if len(inactive_points[0]) == 0:\n",
    "        return model, inactive_ratio_0\n",
    "    \n",
    "    point = np.random.choice(len(inactive_points[0]))\n",
    "    selected = point\n",
    "    \n",
    "    x = inactive_points[0][selected]\n",
    "    y = inactive_points[1][selected]\n",
    "    z = inactive_points[2][selected]\n",
    "    \n",
    "    print(\"selected point\", x, y, z)\n",
    "    \n",
    "    #get the patch of the image that corresponds to the selected point\n",
    "    org_x_start = x * stride\n",
    "    org_y_start = y * stride\n",
    "    org_z_start = z * stride\n",
    "    org_x_end = org_x_start + kernel_size[0]\n",
    "    org_y_end = org_y_start + kernel_size[1]\n",
    "    org_z_end = org_z_start + kernel_size[2]\n",
    "    \n",
    "    patch = image[:, org_x_start:org_x_end, org_y_start:org_y_end, org_z_start:org_z_end, :]\n",
    "    patch = patch.reshape(kernel_size[0], kernel_size[1], kernel_size[2], 1)\n",
    "    new_filter = model.add_filter(patch, epochs = 100, image_x = image)\n",
    "    \n",
    "    separated_new_fms = model.call_seperated_fm(image)\n",
    "    max_map = np.zeros(separated_new_fms[0].shape)\n",
    "    for fm in separated_new_fms:\n",
    "        fm = (fm>model.threshold).numpy().astype(np.float32)\n",
    "        max_map += fm.reshape(separated_new_fms[0].shape)\n",
    "        \n",
    "    inactive_points_check = np.where(max_map == 0)\n",
    "    inactive_ratio_1 = len(inactive_points_check[0])/np.prod(np.shape(max_map))\n",
    "    print(\"inactive ratio after adding filter\", inactive_ratio_1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    show_all_index_maps_3D(model, data_0_9=fm_0_9)\n",
    "    return model, inactive_ratio_1\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def generate_model(img_x, model = None):\n",
    "    image_x = img_x.reshape(1, img_x.shape[0], img_x.shape[1], 1)\n",
    "    last_selected = [-1, -1]\n",
    "\n",
    "    \n",
    "    my_model = model\n",
    "    if model == None:\n",
    "        my_model = extensible_CNN_layer_multi_module_3D()\n",
    "    \n",
    "    filter_size = my_model.kernel_size\n",
    "    stride = my_model.stride\n",
    "    \n",
    "    threshold = my_model.threshold\n",
    "    \n",
    "\n",
    "    print(\"activation and threshold\")\n",
    "    print(my_model.activation, threshold)\n",
    "    for i in range(20): #generate a series of filters\n",
    "        generate_filter(image_x, my_model, image_x.shape[1:])\n",
    "\n",
    "    #print(my_model.activation, len(my_model.filter_list))\n",
    "    return my_model\n",
    "    \n",
    "\n",
    "def get_inactive_ratio(model, image):\n",
    "    \n",
    "    fm_i = model.call_seperated_fm(image)\n",
    "    max_map = np.zeros(fm_i[0].shape)\n",
    "    \n",
    "    for fm in fm_i:\n",
    "        fm = (fm>model.threshold).numpy().astype(np.float32)\n",
    "        max_map += fm.reshape(fm_i[0].shape)\n",
    "        \n",
    "    inactive_ratio = len(np.where(max_map == 0)[0])/np.prod(np.shape(max_map))\n",
    "    return inactive_ratio\n",
    "        \n",
    "    \n",
    "def get_inactive_ratio_list(model, images):\n",
    "    inactive_ratios = []\n",
    "    total = len(images)\n",
    "    counter = 0\n",
    "    tqdm_bar = tqdm.tqdm(total=total)\n",
    "    for img in images:\n",
    "        inactive_ratios.append(get_inactive_ratio(model, img))\n",
    "        counter += 1\n",
    "        #a progress bar\n",
    "        #tqdm\n",
    "        tqdm_bar.update(1)\n",
    "        \n",
    "    \n",
    "    return inactive_ratios\n",
    "\n",
    "def generate_model_on_images(images, model, images_0_9, inactive_ratio_threshold = 0.1, n = 3):\n",
    "    #initialize by generating 2 filters on the first image\n",
    "    if model == None:\n",
    "        model = extensible_CNN_layer_multi_module_3D()\n",
    "    \n",
    "    #model = generate_filter(images[0], model, threshold = model.threshold)\n",
    "    \n",
    "    #loop through the images, generate filters\n",
    "    \n",
    "    inactive_ratios = [0 for i in range(len(images))]\n",
    "    '''\n",
    "    for i in range(len(images)):\n",
    "        print(\"\\nimage \", i)\n",
    "        model, ratio = generate_filter(images[i], model, images[i].shape[1:], fm_0_9=images_0_9)\n",
    "        inactive_ratios[i] = ratio\n",
    "    '''\n",
    "    \n",
    "    #If the model has no filter, first round, generate 1 filter on randomly selected n images\n",
    "    if len(model.filter_list) == 0:\n",
    "        for i in range(n):\n",
    "            image_idx = np.random.randint(len(images))\n",
    "            print(\"\\nimage \", image_idx)\n",
    "            model, ratio = generate_filter(images[image_idx], model, images[image_idx].shape[1:], fm_0_9=images_0_9)\n",
    "            inactive_ratios[image_idx] = ratio\n",
    "        \n",
    "    #then generate 1 filter on the image with the highest inactive ratio\n",
    "    \n",
    "    inactive_ratios = get_inactive_ratio_list(model, images)\n",
    "    \n",
    "    mean_inactive_ratio = np.mean(inactive_ratios)\n",
    "    max_inactive_ratio = np.max(inactive_ratios)\n",
    "    print(\"inactive ratios mean\", mean_inactive_ratio, \"max\", max_inactive_ratio)\n",
    "    \n",
    "    if max_inactive_ratio < inactive_ratio_threshold:\n",
    "        return model, False\n",
    "\n",
    "    #get top n images with highest inactive ratio\n",
    "    top_n_inactive_ratio_idx = np.argsort(inactive_ratios)[-n:]\n",
    "    for i in top_n_inactive_ratio_idx:\n",
    "        print(\"\\nimage \", i)\n",
    "        model, ratio = generate_filter(images[i], model, images[i].shape[1:], fm_0_9=images_0_9)\n",
    "    \n",
    "    \n",
    "    print(model.activation, len(model.filter_list))\n",
    "    \n",
    "    return model, True\n",
    "        \n",
    "\n",
    "def examin_aggregated_conv(images_x_0_9, layer):\n",
    "    figure = plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    fms = layer(np.array(images_x_0_9).reshape(10, image_size, image_size, 1, 1))\n",
    "    for i in range(10):\n",
    "        #print(fms[i].shape)\n",
    "        fm_i = fms[i].numpy().reshape(fms[i].shape[0], fms[i].shape[1], fms.shape[-1])\n",
    "        index_map = np.argmax(fm_i, axis = 2)\n",
    "        #print(fm_i.shape, index_map.shape)\n",
    "        ax_i = figure.add_subplot(2, 5, i+1)\n",
    "        ax_i.imshow(index_map, cmap = \"gist_ncar\")\n",
    "    #show_all_index_maps_3D(data_0_9=images_y_0_9, model=my_model)\n",
    "    \n",
    "      \n",
    "\n",
    "#get the images 0 - 9\n",
    "images_x_0_9 = []\n",
    "images_y_0_9 = []\n",
    "image_size = len(train_images[0])\n",
    "n_shot = 1\n",
    "for label_idx in range(10):\n",
    "    for i in range(n_shot):\n",
    "        image_label_i = np.where(train_labels == label_idx)[0]\n",
    "        image_x_i = train_images[image_label_i][i].reshape(1,image_size,image_size,1, 1).astype('float64')\n",
    "        image_y_i = label_idx\n",
    "        one_hot_y_i = tf.one_hot(image_y_i, 10).numpy().reshape(1,10)\n",
    "        #train_one_shot(image_x_i, one_hot_y_i)\n",
    "        images_x_0_9.append(image_x_i)\n",
    "        images_y_0_9.append(one_hot_y_i)\n",
    "    \n",
    "print(len(images_x_0_9))\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_class_n(images, labels, class_count = 5, labelled_img_count = 1000):\n",
    "    \"\"\"_summary_\n",
    "    \n",
    "    Description:\n",
    "        This function returns a list of images and labels in the order of class 0 * 1000, class 1 * 1000, ... class n * 1000\n",
    "\n",
    "    Args:\n",
    "        images (_type_): _description_\n",
    "        labels (_type_): _description_\n",
    "        class_count (int, optional): _description_. Defaults to 5.\n",
    "        labelled_img_count (int, optional): _description_. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    images_class_n = []\n",
    "    labels_class_n = []\n",
    "    for i in range(class_count):\n",
    "        for j in range(labelled_img_count):\n",
    "            img_j = images[np.where(labels == i)[0][j]]\n",
    "            images_class_n.append(img_j.reshape(1, image_size, image_size, 1, 1))\n",
    "            labels_class_n.append(i)\n",
    "    return images_class_n, labels_class_n\n",
    "\n",
    "\n",
    "images_1000_0_4, labels_1000_0_4 = get_images_class_n(train_images, train_labels, class_count = 5, labelled_img_count = 1000)\n",
    "images_1000_5_9, labels_1000_5_9 = get_images_class_n(train_images, train_labels, class_count = 5, labelled_img_count = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate l0 model on images_1000_0_4\n",
    "epochs = 10\n",
    "model_l0 = None\n",
    "continue_generation = True\n",
    "for epoch in range(epochs):\n",
    "    if not continue_generation:\n",
    "        break\n",
    "    print(\"epoch\", epoch)\n",
    "    model_l0, continue_generation = generate_model_on_images(images_1000_0_4, model_l0, images_x_0_9, inactive_ratio_threshold = 0.01, n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate l1 model on images_1000_5_9\n",
    "\n",
    "epochs = 10\n",
    "continue_generation = True\n",
    "for epoch in range(epochs):\n",
    "    if not continue_generation:\n",
    "        break\n",
    "    print(\"epoch\", epoch)\n",
    "    model_l0, continue_generation = generate_model_on_images(images_1000_5_9, model_l0, images_x_0_9, inactive_ratio_threshold = 0.01, n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the mnist dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images_mnist, train_labels_mnist), (test_images_mnist, test_labels_mnist) = mnist.load_data()\n",
    "train_images_mnist = train_images_mnist.reshape(train_images_mnist.shape[0], 28, 28, 1, 1).astype('float64')\n",
    "train_images_mnist = train_images_mnist / 255.0\n",
    "test_images_mnist = test_images_mnist.reshape(test_images_mnist.shape[0], 28, 28, 1, 1).astype('float64')\n",
    "test_images_mnist = test_images_mnist / 255.0\n",
    "#visualize the 0-9 images of mnist\n",
    "mnist_x_0_9 = []\n",
    "for i in range(10):\n",
    "    mnist_x_0_9.append(train_images_mnist[np.where(train_labels_mnist == i)[0][0]].reshape(1,28,28,1,1).astype('float64'))\n",
    "show_all_index_maps_3D(data_0_9=mnist_x_0_9, model=model_l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate more filters on mnist\n",
    "continue_generation = True\n",
    "for epoch in range(epochs):\n",
    "    if not continue_generation:\n",
    "        break\n",
    "    print(\"epoch\", epoch)\n",
    "    model_l0, continue_generation = generate_model_on_images(mnist_x_0_9, model_l0, images_x_0_9, inactive_ratio_threshold = 0.01, n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a multi-module model for classification\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1208a9daaafa5a13e1cbea10a073c0fad837bdf60ee955a864adc6dee7f94e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
